{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /workspaces/lexi-navigator-server-api/.venv/lib/python3.10/site-packages (1.14.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /workspaces/lexi-navigator-server-api/.venv/lib/python3.10/site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /workspaces/lexi-navigator-server-api/.venv/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /workspaces/lexi-navigator-server-api/.venv/lib/python3.10/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /workspaces/lexi-navigator-server-api/.venv/lib/python3.10/site-packages (from openai) (2.6.4)\n",
      "Requirement already satisfied: sniffio in /workspaces/lexi-navigator-server-api/.venv/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /workspaces/lexi-navigator-server-api/.venv/lib/python3.10/site-packages (from openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /workspaces/lexi-navigator-server-api/.venv/lib/python3.10/site-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: idna>=2.8 in /workspaces/lexi-navigator-server-api/.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /workspaces/lexi-navigator-server-api/.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /workspaces/lexi-navigator-server-api/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /workspaces/lexi-navigator-server-api/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /workspaces/lexi-navigator-server-api/.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /workspaces/lexi-navigator-server-api/.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /workspaces/lexi-navigator-server-api/.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "!export OPENAI_API_KEY='sk-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo-16k\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You are a translation expert. Returns the translation results as JSON results, including the following keys: {t:<Translation Results>, d:<Detection Language Code>}\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Translate the text delimited by triple backticks  into ZH ：\\n```\\nControls randomness: Lowering results in less random completions.As the temperature approaches zero, the model will become deterministic and repetitive.\\n```\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Translate the text delimited by triple backticks  into ZH ：\\n```hello```\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=1,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-97JuYema3T85NkidapsevZIIewAuc', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"t\": \"你好\",\\n  \"d\": \"en\"\\n}', role='assistant', function_call=None, tool_calls=None))], created=1711531862, model='gpt-3.5-turbo-16k-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=17, prompt_tokens=105, total_tokens=122))\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"t\": \"控制随机性：降低结果会导致更少的随机完成。当温度接近零时，模型变得确定性和重复。\",\n",
      "  \"d\": \"en\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_single(prompt, model=\"gpt-3.5-turbo-16k\", system_prompt=\"You are a CHATGPT model, helping me complete the coding work\",**kwargs):\n",
    "    reqArgs = {\n",
    "        \"temperature\":1,\n",
    "        \"top_p\":1,\n",
    "        \"frequency_penalty\":0,\n",
    "        \"presence_penalty\":0\n",
    "    }\n",
    "    reqArgs.update(kwargs)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        **reqArgs\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
